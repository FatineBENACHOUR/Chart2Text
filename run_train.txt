python3 model/train.py \
    --model_path "experiments" \
    --exp_name "chart2text" \
    --exp_id "run1" \
    --train_cs_table_path data/train/trainData.txt.pth \
    --train_sm_table_path data/train/trainData.txt.pth \
    --train_sm_summary_path data/train/trainSummary.txt.pth \
    --valid_table_path data/valid/validData.txt.pth \
    --valid_summary_path data/valid/validSummary.txt.pth \
    --cs_step True \
    --lambda_cs "1" \
    --sm_step True \
    --lambda_sm "1" \
    --label_smoothing 0.05 \
    --sm_step_with_cc_loss False \
    --sm_step_with_cs_proba False \
    --share_inout_emb True \
    --share_srctgt_emb False \
    --sinusoidal_embeddings False \
    --emb_dim 512 \
    --enc_n_layers 1 \
    --dec_n_layers 6 \
    --dropout 0.1 \
    --save_periodic 40 \
    --batch_size 6 \
    --beam_size 4 \
    --epoch_size 1000 \
    --max_epoch 121 \
    --eval_bleu True \
    --validation_metrics _cs_f1


python3 model/summarize.py --model_path may21relu-80.pth --table_path data/test/testData.txt \
--output_path results/may21/templateOutput_521rp80_beam=4_batch=8.txt --beam_size 4 --batch_size 8


python3 model/summarize.py --model_path periodic-75.pth --table_path data_testing/trainData.txt \
--output_path data_testing/504Test_beam=4_batch=8.txt --beam_size 4 --batch_size 8

perl model/src/evaluation/multi-bleu.perl data/test/testOriginalSummary.txt < results/may21/generated-521r-p80.txt

May 06:
200 epochs:
BLEU = 21.10, 51.1/25.2/16.9/12.8 (BP=0.917, ratio=0.920, hyp_len=37841, ref_len=41116)

100 epochs:
BLEU = 21.77, 53.7/27.9/19.0/14.5 (BP=0.858, ratio=0.867, hyp_len=35657, ref_len=41116)

May 11:
100 epochs:
BLEU = 23.33, 56.5/31.1/22.0/17.4 (BP=0.815, ratio=0.831, hyp_len=34147, ref_len=41116)

May 13: positional embeddings
BLEU = 23.65, 56.4/31.1/21.9/17.3 (BP=0.828, ratio=0.841, hyp_len=34572, ref_len=41116)

May 14/15:
epoch 80
BLEU = 22.17, 47.0/23.8/16.5/13.0 (BP=1.000, ratio=1.044, hyp_len=42936, ref_len=41116)

epoch 220
BLEU = 19.49, 44.5/21.2/14.2/10.8 (BP=1.000, ratio=1.071, hyp_len=44017, ref_len=41116)

epoch 330
fluency decreases, accuracy is hit/miss
BLEU = 20.72, 45.7/22.6/15.3/11.7 (BP=1.000, ratio=1.055, hyp_len=43385, ref_len=41116)

may 19: increase # encoder / decoder layers and embedding size:
predicts the same sentence each time

may 20: gelu (and maybe causal lm)
BLEU = 20.84, 44.6/22.4/15.6/12.1 (BP=1.000, ratio=1.096, hyp_len=45066, ref_len=41117)

may 21 gelu
BLEU = 21.85, 45.9/23.4/16.3/13.0 (BP=1.000, ratio=1.065, hyp_len=43795, ref_len=41117)

may 21 relu
BLEU = 22.43, 47.3/24.3/16.8/13.1 (BP=1.000, ratio=1.036, hyp_len=42611, ref_len=41117)
